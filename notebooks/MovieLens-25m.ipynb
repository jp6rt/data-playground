{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6995e9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f8554bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_prefix = '/home/joeyresuento/Projects/data_training/data_sets/ml-25m'\n",
    "# movies = pd.read_csv(f'{path_prefix}/movies.csv')\n",
    "# ratings = pd.read_csv(f'{path_prefix}/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93fe86b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/03 14:37:26 WARN Utils: Your hostname, aljresuento1 resolves to a loopback address: 127.0.1.1; using 192.168.254.174 instead (on interface enp1s0f0)\n",
      "24/05/03 14:37:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/03 14:37:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"MyApp\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2701cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = spark.read.option(\"header\", True).csv(f'{path_prefix}/movies.csv')\n",
    "ratings_df = spark.read.option(\"header\", True).csv(f'{path_prefix}/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90479f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df.createOrReplaceTempView('ratings')\n",
    "movies_df.createOrReplaceTempView('movies')\n",
    "# spark.sql(\"SELECT COUNT(1) FROM movies\").show()\n",
    "# spark.sql(\"SELECT COUNT(1) FROM ratings\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e53808e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top100_highest_rated_movies = spark.sql(\"SELECT \\\n",
    "#    movieId, rating, COUNT(1) as count \\\n",
    "#    FROM ratings \\\n",
    "#    GROUP BY movieId, rating \\\n",
    "#    ORDER BY rating, count DESC LIMIT 100\")\n",
    "\n",
    "# top100_highest_rated_movie_ids = top100_highest_rated_movies \\\n",
    "#    .rdd.map(lambda r: int(r.movieId)) \\\n",
    "#    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b4f9b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.printSchema()\n",
    "ratings_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f59c1f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings_df = spark.sql(\"SELECT m.movieId, m.title, m.genres, r.userId, r.rating, r.timestamp \\\n",
    "FROM movies m INNER JOIN ratings r ON m.movieId = r.movieId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3459156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_ratings_df.take(10)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f577e6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_row(row):\n",
    "    year = datetime.fromtimestamp(int(row.timestamp)).year\n",
    "    return Row(\n",
    "        movieId=int(row.movieId),\n",
    "        title=row.title,\n",
    "        genres=row.genres,\n",
    "        userId=int(row.userId),\n",
    "        rating=float(row.rating),\n",
    "        timestamp=int(row.timestamp),\n",
    "        year=year\n",
    "    )\n",
    "\n",
    "enriched_movie_ratings = movie_ratings_df.rdd.map(enrich_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "08269cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: long (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- userId: long (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enriched_movie_ratings_df = spark.createDataFrame(enriched_movie_ratings)\n",
    "enriched_movie_ratings_df.createOrReplaceTempView('movies_ratings')\n",
    "enriched_movie_ratings_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "677a4820",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_count_by_year = enriched_movie_ratings_df.rdd \\\n",
    "    .map(lambda r: (r.year, 1)) \\\n",
    "    .reduceByKey(lambda a, b: a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fd5f5db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_count_by_year_list = ratings_count_by_year.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "661940d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2016, 1756856),\n",
       " (2000, 1737245),\n",
       " (2017, 1690321),\n",
       " (2001, 1057762),\n",
       " (2002, 777868),\n",
       " (2018, 1310712),\n",
       " (2019, 1202383),\n",
       " (2003, 920780),\n",
       " (2004, 1047089),\n",
       " (2005, 1613232),\n",
       " (2006, 1039236),\n",
       " (2007, 930435),\n",
       " (2008, 1019216),\n",
       " (2009, 810134),\n",
       " (2010, 792767),\n",
       " (2011, 676488),\n",
       " (1995, 3),\n",
       " (1996, 1429280),\n",
       " (2012, 634829),\n",
       " (1997, 626849),\n",
       " (2013, 516094),\n",
       " (1998, 272153),\n",
       " (2014, 478141),\n",
       " (2015, 1604061),\n",
       " (1999, 1056161)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_count_by_year_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b2b326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
